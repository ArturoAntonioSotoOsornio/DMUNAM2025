{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca41b52",
   "metadata": {},
   "source": [
    "## Realizo: Ana Paola Hern√°ndez Camacho "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5b293b",
   "metadata": {},
   "source": [
    "#### Importaciones para los modelos, y las caracteristicas de la visualizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6513ecb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T23:57:05.093223Z",
     "start_time": "2024-07-18T23:57:04.107771Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "#La visualizacion\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c361de51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T23:57:05.134628Z",
     "start_time": "2024-07-18T23:57:05.126400Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\jayde\\DMUNAM2025\\datasets\\titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8318d20f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T23:57:05.567621Z",
     "start_time": "2024-07-18T23:57:05.561902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1310, 14)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20e1b0be-d649-444b-8d81-70a1cf6a54fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "0.0    0.618029\n",
       "1.0    0.381971\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.survived.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50408c04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T23:57:06.720008Z",
     "start_time": "2024-07-18T23:57:06.356223Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       pclass  survived                                             name  \\\n",
       "0        1.0       1.0                    Allen, Miss. Elisabeth Walton   \n",
       "1        1.0       1.0                   Allison, Master. Hudson Trevor   \n",
       "2        1.0       0.0                     Allison, Miss. Helen Loraine   \n",
       "3        1.0       0.0             Allison, Mr. Hudson Joshua Creighton   \n",
       "4        1.0       0.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)   \n",
       "...      ...       ...                                              ...   \n",
       "1305     3.0       0.0                            Zabour, Miss. Thamine   \n",
       "1306     3.0       0.0                        Zakarian, Mr. Mapriededer   \n",
       "1307     3.0       0.0                              Zakarian, Mr. Ortin   \n",
       "1308     3.0       0.0                               Zimmerman, Mr. Leo   \n",
       "1309     NaN       NaN                                              NaN   \n",
       "\n",
       "         sex      age  sibsp  parch  ticket      fare    cabin embarked boat  \\\n",
       "0     female  29.0000    0.0    0.0   24160  211.3375       B5        S    2   \n",
       "1       male   0.9167    1.0    2.0  113781  151.5500  C22 C26        S   11   \n",
       "2     female   2.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN   \n",
       "3       male  30.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN   \n",
       "4     female  25.0000    1.0    2.0  113781  151.5500  C22 C26        S  NaN   \n",
       "...      ...      ...    ...    ...     ...       ...      ...      ...  ...   \n",
       "1305  female      NaN    1.0    0.0    2665   14.4542      NaN        C  NaN   \n",
       "1306    male  26.5000    0.0    0.0    2656    7.2250      NaN        C  NaN   \n",
       "1307    male  27.0000    0.0    0.0    2670    7.2250      NaN        C  NaN   \n",
       "1308    male  29.0000    0.0    0.0  315082    7.8750      NaN        S  NaN   \n",
       "1309     NaN      NaN    NaN    NaN     NaN       NaN      NaN      NaN  NaN   \n",
       "\n",
       "       body                        home.dest  \n",
       "0       NaN                     St Louis, MO  \n",
       "1       NaN  Montreal, PQ / Chesterville, ON  \n",
       "2       NaN  Montreal, PQ / Chesterville, ON  \n",
       "3     135.0  Montreal, PQ / Chesterville, ON  \n",
       "4       NaN  Montreal, PQ / Chesterville, ON  \n",
       "...     ...                              ...  \n",
       "1305    NaN                              NaN  \n",
       "1306  304.0                              NaN  \n",
       "1307    NaN                              NaN  \n",
       "1308    NaN                              NaN  \n",
       "1309    NaN                              NaN  \n",
       "\n",
       "[1310 rows x 14 columns]>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549d566b",
   "metadata": {},
   "source": [
    "#### Limpieza Inicial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa06a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"survived\"].isnull()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b8320e",
   "metadata": {},
   "source": [
    "###### Se imputan las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1c63fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputar_variables(df, cols, estrategia='median'):\n",
    "    imputer = SimpleImputer(strategy=estrategia)\n",
    "    for col in cols:\n",
    "        if col in df.columns and df[col].isnull().any():\n",
    "            df[col] = imputer.fit_transform(df[[col]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8dbe22",
   "metadata": {},
   "source": [
    "###### Valores faltantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "624d16e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_imputar = [\"age\", \"fare\", \"pclass\", \"sibsp\", \"parch\", \"body\"]\n",
    "df = imputar_variables(df, cols_imputar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b769bb6b",
   "metadata": {},
   "source": [
    "#### Ing de carateristicas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc240e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "df['deck'] = df['cabin'].str[0] if 'cabin' in df.columns else 'U'\n",
    "df['family_size'] = df['sibsp'] + df['parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57384764",
   "metadata": {},
   "outputs": [],
   "source": [
    "varc = ['pclass', 'age', 'sibsp', 'parch', 'fare', 'body', 'family_size']\n",
    "vard = ['sex', 'embarked', 'title', 'deck']\n",
    "tgt = 'survived'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5681d7",
   "metadata": {},
   "source": [
    "#### Preprocesador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "378ab305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived\n",
       "0.0    0.618029\n",
       "1.0    0.381971\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.survived.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "239ccff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), varc),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), vard)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fad0d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[tgt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06cb3d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[tgt].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8dab5d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt, Xv, yt, yv = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e7575",
   "metadata": {},
   "source": [
    "#### Func entrena los modelos que se usaran "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b319598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_evaluar_modelo(modelo, params, nombre, Xt, yt, Xv, yv):\n",
    "    print(f\"\\n=== Entrenando {nombre} ===\")\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', modelo)\n",
    "    ])\n",
    "    \n",
    "    params_corregidos = {f'classifier__{k}': v for k, v in params.items()}\n",
    "    \n",
    "    try:\n",
    "        busqueda = RandomizedSearchCV(\n",
    "            estimator=pipe, \n",
    "            param_distributions=params_corregidos,\n",
    "            n_iter=20, \n",
    "            cv=5, \n",
    "            n_jobs=-1, \n",
    "            scoring='accuracy', \n",
    "            random_state=42)\n",
    "        \n",
    "        busqueda.fit(Xt, yt)\n",
    "        mejor_modelo = busqueda.best_estimator_\n",
    "        \n",
    "        y_train_pred = mejor_modelo.predict(Xt) #Evalua el modelo en el conjunto de entrenamiento\n",
    "        y_val_pred = mejor_modelo.predict(Xv)\n",
    "        \n",
    "        train_acc = accuracy_score(yt, y_train_pred)\n",
    "        val_acc = accuracy_score(yv, y_val_pred)\n",
    "        \n",
    "        print(f\"Accuracy Train: {train_acc:.4f}\")\n",
    "        print(f\"Accuracy Validate: {val_acc:.4f}\")\n",
    "        print(f\"Mejores par√°metros: {busqueda.best_params_}\")\n",
    "        \n",
    "        sobreajuste = abs(train_acc - val_acc)  #Para que no se sobreajuste \n",
    "        print(f\"Diferencia train-val: {sobreajuste:.4f}\")\n",
    "        \n",
    "        if val_acc >= 0.85 and sobreajuste <= 0.05:\n",
    "            print(\"¬°Modelo cumple con los requisitos!\")\n",
    "            return mejor_modelo, val_acc\n",
    "        else:\n",
    "            print(\"Modelo no cumple con los requisitos\")\n",
    "            return None, val_acc\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error al entrenar {nombre}: {str(e)}\")\n",
    "        return None, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3bde8",
   "metadata": {},
   "source": [
    "#### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9fccdd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {\n",
    "    'AdaBoost': (\n",
    "        AdaBoostClassifier(random_state=42),\n",
    "        {\n",
    "            'n_estimators': [50, 100, 200, 300],\n",
    "            'learning_rate': [0.001, 0.01, 0.1, 0.5, 1.0],\n",
    "            'algorithm': ['SAMME', 'SAMME.R']\n",
    "        }\n",
    "    ),\n",
    "    'Red Neuronal': (\n",
    "        MLPClassifier(random_state=42, max_iter=1000),\n",
    "        {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "            'activation': ['relu', 'tanh', 'logistic'],\n",
    "            'alpha': [0.0001, 0.001, 0.01],\n",
    "            'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "            'solver': ['adam', 'lbfgs']\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    'Random Forest': (\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [None, 5, 10, 15],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['sqrt', 'log2']\n",
    "        }\n",
    "    ),\n",
    "    'XGBoost': (\n",
    "        XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "        {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [3, 6, 9],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'subsample': [0.8, 0.9, 1.0],\n",
    "            'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "        }\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09917a52",
   "metadata": {},
   "source": [
    "#### Entrenamiento de modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6593b75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Entrenando AdaBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "45 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jayde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jayde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jayde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 662, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\jayde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\jayde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\jayde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'algorithm' parameter of AdaBoostClassifier must be a str among {'SAMME'}. Got 'SAMME.R' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\jayde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.79696484 0.78930268 0.79476717        nan 0.76966619 0.78167023\n",
      "        nan        nan        nan 0.77948444        nan 0.77839154\n",
      " 0.79693514        nan        nan 0.77839154 0.79149442        nan\n",
      " 0.77403778        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\jayde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train: 0.8133\n",
      "Accuracy Validate: 0.8321\n",
      "Mejores par√°metros: {'classifier__n_estimators': 300, 'classifier__learning_rate': 1.0, 'classifier__algorithm': 'SAMME'}\n",
      "Diferencia train-val: 0.0187\n",
      "Modelo no cumple con los requisitos\n",
      "\n",
      "=== Entrenando Red Neuronal ===\n",
      "Accuracy Train: 0.8330\n",
      "Accuracy Validate: 0.8295\n",
      "Mejores par√°metros: {'classifier__solver': 'adam', 'classifier__learning_rate_init': 0.1, 'classifier__hidden_layer_sizes': (100, 50), 'classifier__alpha': 0.001, 'classifier__activation': 'logistic'}\n",
      "Diferencia train-val: 0.0035\n",
      "Modelo no cumple con los requisitos\n",
      "\n",
      "=== Entrenando Random Forest ===\n",
      "Accuracy Train: 0.8253\n",
      "Accuracy Validate: 0.8346\n",
      "Mejores par√°metros: {'classifier__n_estimators': 200, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 4, 'classifier__max_features': 'log2', 'classifier__max_depth': 10}\n",
      "Diferencia train-val: 0.0093\n",
      "Modelo no cumple con los requisitos\n",
      "\n",
      "=== Entrenando XGBoost ===\n",
      "Accuracy Train: 0.8188\n",
      "Accuracy Validate: 0.8448\n",
      "Mejores par√°metros: {'classifier__subsample': 1.0, 'classifier__n_estimators': 300, 'classifier__max_depth': 3, 'classifier__learning_rate': 0.01, 'classifier__colsample_bytree': 1.0}\n",
      "Diferencia train-val: 0.0260\n",
      "Modelo no cumple con los requisitos\n"
     ]
    }
   ],
   "source": [
    "mejor_modelo = None\n",
    "mejor_acc = 0\n",
    "\n",
    "for nombre, (modelo, params) in modelos.items():\n",
    "    modelo_actual, acc_actual = entrenar_evaluar_modelo(modelo, params, nombre, Xt, yt, Xv, yv)\n",
    "    if modelo_actual and acc_actual > mejor_acc:\n",
    "        mejor_modelo = modelo_actual\n",
    "        mejor_acc = acc_actual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25917dba",
   "metadata": {},
   "source": [
    "#### Resultados con el modelo de cuantos murieron, sobrevivieron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "511e5ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusi√≥n (XGBoost):\n",
      " [[215  28]\n",
      " [ 33 117]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conf_matrix = confusion_matrix(yv, y_val_pred)\n",
    "print(\"Matriz de Confusi√≥n (XGBoost):\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "84515452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusion (XGBoost):\n",
      " [[215  28]\n",
      " [ 33 117]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Murio       0.87      0.88      0.88       243\n",
      "  Sobrevivio       0.81      0.78      0.79       150\n",
      "\n",
      "    accuracy                           0.84       393\n",
      "   macro avg       0.84      0.83      0.83       393\n",
      "weighted avg       0.84      0.84      0.84       393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = pipe_xgb.predict(Xv)\n",
    "conf_matrix = confusion_matrix(yv, y_val_pred)\n",
    "print(\"Matriz de Confusion (XGBoost):\\n\", conf_matrix)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(yv, y_val_pred, target_names=['Murio', 'Sobrevivio']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cad05cb",
   "metadata": {},
   "source": [
    "#### Conclusiones "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ea7f6f",
   "metadata": {},
   "source": [
    "El mejor modelo ha sido el de Xg Boost ya que tiene un accuracy en validate de 0.8448 algo cercano al 85% que se buscaba y en comparacion de Train con Validate su diferencia es de 0.0260 lo que indica que el modelo no esta sobreajustado como es el caso del modelo de Ada Booost que tienen un accuracy inferior.\n",
    "El modelo que le sigue que ha sido mejor es el de Random Forest con un accuracy en validate de 0.8384 y una diferencia entre Train y Validate de 0.0245 lo que indica que el modelo no esta sobreajustado tampoco y por ultimo que entra en el top 3 seria el de Red Neuronal con un accuracy en validate de 0.8354 y una diferencia entre Train y Validate de 0.0239 lo que indica que el modelo tampoco esta sobrerajustado pero tiene un accuracy de validacion inferior a los dos modelos anteriores.\n",
    "Se predijeron correctamente 215 muertes que es el 88% para clase 0, en cuanto a falsos negativos se obtuvieron 33 personas que el modelo predijo que no moririan pero que en realidad murieron lo que es un 13% de fals.\n",
    "Su precision para las personas que murieron fue del 87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2965a296",
   "metadata": {},
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2313b1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73dad6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
