{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cufflinks as cf\n",
        "from sklearn.impute import SimpleImputer\n",
        "from scipy.stats import ks_2samp\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "\n",
        "# Configuración inicial\n",
        "pd.set_option(\"display.max_columns\", 30)\n",
        "pd.set_option(\"display.max_rows\", 3000)\n",
        "cf.go_offline()\n",
        "\n",
        "# 1. Carga y exploración inicial de datos\n",
        "df = pd.read_csv(\"/titanic.csv\")\n",
        "print(\"Forma inicial del dataset:\", df.shape)\n",
        "print(\"\\nDistribución de survived:\\n\", df.survived.value_counts(normalize=True))\n",
        "\n",
        "# 2. Análisis de datos faltantes\n",
        "def completitud_datos_nulos(df):\n",
        "    return df.isnull().sum().sort_values(ascending=False) / df.shape[0]\n",
        "\n",
        "print(\"\\nPorcentaje de valores nulos por columna:\")\n",
        "print(completitud_datos_nulos(df))\n",
        "\n",
        "# 3. Limpieza inicial\n",
        "df = df[(~df[\"survived\"].isnull()) & (~df[\"pclass\"].isnull()) & (~df[\"fare\"].isnull())]\n",
        "\n",
        "# 4. Ingeniería de características MEJORADA\n",
        "df['sex_encoded'] = df['sex'].map({'male': 0, 'female': 1})\n",
        "df['family_size'] = df['sibsp'] + df['parch'] + 1  # +1 para incluir al pasajero\n",
        "df['is_alone'] = (df['family_size'] == 1).astype(int)\n",
        "df['fare_per_person'] = df['fare'] / df['family_size']\n",
        "df['age_class'] = df['age'] * df['pclass']  # Interacción importante\n",
        "\n",
        "# 5. Imputación de valores nulos MEJORADA\n",
        "def complete_continuous_variables(df, cols, strategy='median'):\n",
        "    imputer = SimpleImputer(strategy=strategy)\n",
        "    for col in cols:\n",
        "        if col in df.columns:\n",
        "            original = df[col].dropna()\n",
        "            if len(original) > 0:  # Solo imputar si hay valores no nulos\n",
        "                df[col] = imputer.fit_transform(df[[col]])\n",
        "                # Verificación KS\n",
        "                imputed = df.loc[original.index, col]\n",
        "                ks_stat = ks_2samp(original, imputed).statistic\n",
        "                print(f\"KS-test para {col}: {ks_stat:.4f}\")\n",
        "                if ks_stat >= 0.1:\n",
        "                    print(f\"¡Advertencia: Gran diferencia en distribución para {col}!\")\n",
        "    return df\n",
        "\n",
        "# Imputar variables importantes\n",
        "df = complete_continuous_variables(df, [\"age\", \"fare\", \"body\", \"fare_per_person\"])\n",
        "\n",
        "# 6. Selección de variables finales\n",
        "varc = [\"pclass\", \"fare\", \"age\", \"sex_encoded\", \"family_size\",\n",
        "        \"is_alone\", \"fare_per_person\", \"age_class\"]\n",
        "tgt = \"survived\"\n",
        "\n",
        "# 7. Preparación de datos\n",
        "X = df[varc].copy()\n",
        "y = df[tgt].copy().astype(int)\n",
        "\n",
        "# Escalado para modelos que lo requieran\n",
        "sc = MinMaxScaler()\n",
        "Xs = pd.DataFrame(sc.fit_transform(X), columns=varc)\n",
        "\n",
        "# División estratificada MEJORADA\n",
        "Xt, Xv, yt, yv = train_test_split(Xs, y, train_size=0.7, random_state=42, stratify=y)\n",
        "\n",
        "# 8. Función de entrenamiento MEJORADA\n",
        "def entrenar(modelo, param, X, y):\n",
        "    grid = RandomizedSearchCV(\n",
        "        estimator=modelo,\n",
        "        param_distributions=param,\n",
        "        n_iter=100,  # Más iteraciones para mejor búsqueda\n",
        "        cv=5,        # Más folds para mejor validación\n",
        "        scoring='roc_auc',\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        verbose=1\n",
        "    )\n",
        "    grid.fit(X, y)\n",
        "    print(f\"\\nMejores parámetros encontrados: {grid.best_params_}\")\n",
        "    print(f\"Mejor puntuación AUC-ROC: {grid.best_score_:.4f}\")\n",
        "    return grid.best_estimator_, grid.best_score_, grid.best_params_\n",
        "\n",
        "# 9. Optimización de Random Forest MEJORADA\n",
        "param_rf = {\n",
        "    'n_estimators': range(100, 501, 50),\n",
        "    'max_depth': range(5, 21),\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'bootstrap': [True, False],\n",
        "    'class_weight': ['balanced', 'balanced_subsample', None],\n",
        "    'random_state': [42]\n",
        "}\n",
        "\n",
        "print(\"\\nEntrenando Random Forest...\")\n",
        "modelo_rf = RandomForestClassifier()\n",
        "best_rf, score_rf, params_rf = entrenar(modelo_rf, param_rf, Xt, yt)\n",
        "\n",
        "# 10. Función de métricas MEJORADA\n",
        "def metricas(modelo, Xt, Xv, yt, yv):\n",
        "    probas_train = modelo.predict_proba(Xt)[:, 1]\n",
        "    probas_val = modelo.predict_proba(Xv)[:, 1]\n",
        "\n",
        "    return {\n",
        "        'train_auc': roc_auc_score(yt, probas_train),\n",
        "        'val_auc': roc_auc_score(yv, probas_val),\n",
        "        'diff': abs(roc_auc_score(yt, probas_train) - roc_auc_score(yv, probas_val))\n",
        "    }\n",
        "\n",
        "# 11. Evaluación final MEJORADA\n",
        "results_rf = metricas(best_rf, Xt, Xv, yt, yv)\n",
        "print(\"\\nResultados finales Random Forest:\")\n",
        "print(f\"AUC-ROC Entrenamiento: {results_rf['train_auc']:.4f}\")\n",
        "print(f\"AUC-ROC Validación: {results_rf['val_auc']:.4f}\")\n",
        "print(f\"Diferencia: {results_rf['diff']:.4f}\")\n",
        "\n",
        "# 12. Análisis de overfitting\n",
        "if results_rf['diff'] > 0.1:\n",
        "    print(\"\\n¡Advertencia: Posible overfitting! Diferencia > 10%\")\n",
        "elif results_rf['diff'] > 0.05:\n",
        "    print(\"\\nAdvertencia: Moderada diferencia entre train/validation\")\n",
        "else:\n",
        "    print(\"\\nEl modelo generaliza bien. Diferencias mínimas.\")\n",
        "\n",
        "# 13. Recomendaciones según resultados\n",
        "if results_rf['val_auc'] >= 0.85:\n",
        "    print(\"\\n¡Objetivo alcanzado! Modelo con AUC-ROC >= 85%\")\n",
        "else:\n",
        "    print(\"\\nRecomendaciones para mejorar:\")\n",
        "    print(\"- Añadir más variables relevantes (ej: título extraído del nombre)\")\n",
        "    print(\"- Probar técnicas avanzadas de imputación (KNN imputer)\")\n",
        "    print(\"- Experimentar con más iteraciones en la búsqueda de hiperparámetros\")\n",
        "    print(\"- Ajustar balance de clases con técnicas de muestreo (SMOTE)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "aTDR8PKb1m5k",
        "outputId": "5fd926ac-8b26-46cc-982d-1623ed00f5a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma inicial del dataset: (1310, 14)\n",
            "\n",
            "Distribución de survived:\n",
            " survived\n",
            "0.0    0.618029\n",
            "1.0    0.381971\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Porcentaje de valores nulos por columna:\n",
            "body         0.907634\n",
            "cabin        0.774809\n",
            "boat         0.629008\n",
            "home.dest    0.431298\n",
            "age          0.201527\n",
            "embarked     0.002290\n",
            "fare         0.001527\n",
            "sibsp        0.000763\n",
            "name         0.000763\n",
            "survived     0.000763\n",
            "pclass       0.000763\n",
            "sex          0.000763\n",
            "parch        0.000763\n",
            "ticket       0.000763\n",
            "dtype: float64\n",
            "KS-test para age: 0.0000\n",
            "KS-test para fare: 0.0000\n",
            "KS-test para body: 0.0000\n",
            "KS-test para fare_per_person: 0.0000\n",
            "\n",
            "Entrenando Random Forest...\n",
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "\n",
            "Mejores parámetros encontrados: {'random_state': 42, 'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 5, 'class_weight': None, 'bootstrap': False}\n",
            "Mejor puntuación AUC-ROC: 0.8358\n",
            "\n",
            "Resultados finales Random Forest:\n",
            "AUC-ROC Entrenamiento: 0.9007\n",
            "AUC-ROC Validación: 0.8908\n",
            "Diferencia: 0.0099\n",
            "\n",
            "El modelo generaliza bien. Diferencias mínimas.\n",
            "\n",
            "¡Objetivo alcanzado! Modelo con AUC-ROC >= 85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Configuración para evitar warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 1. Carga y limpieza inicial de datos\n",
        "df = pd.read_csv(\"/titanic.csv\")\n",
        "\n",
        "# 2. Ingeniería de características robusta\n",
        "def feature_engineering(df):\n",
        "    # Extraer título del nombre\n",
        "    df['title'] = df['name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "    df['title'] = df['title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don',\n",
        "                                     'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "    df['title'] = df['title'].replace('Mlle', 'Miss')\n",
        "    df['title'] = df['title'].replace('Ms', 'Miss')\n",
        "    df['title'] = df['title'].replace('Mme', 'Mrs')\n",
        "\n",
        "    # Familia y acompañantes\n",
        "    df['family_size'] = df['sibsp'] + df['parch'] + 1\n",
        "    df['is_alone'] = (df['family_size'] == 1).astype(int)\n",
        "\n",
        "    # Manejo seguro de fare_per_person\n",
        "    df['fare_per_person'] = df['fare'] / df['family_size'].replace(0, 1)  # Evitar división por cero\n",
        "    df['fare_per_person'] = df['fare_per_person'].replace([np.inf, -np.inf], np.nan)  # Reemplazar infinitos\n",
        "\n",
        "    # Interacciones importantes\n",
        "    df['age_class'] = df['pclass'] * df['age'].fillna(df['age'].median())\n",
        "\n",
        "    # Características de cabina\n",
        "    df['cabin_known'] = (~df['cabin'].isnull()).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = feature_engineering(df)\n",
        "\n",
        "# 3. Selección y limpieza final de variables\n",
        "cat_features = ['sex', 'embarked', 'title', 'pclass', 'is_alone', 'cabin_known']\n",
        "num_features = ['age', 'fare', 'family_size', 'fare_per_person', 'age_class']\n",
        "all_features = cat_features + num_features\n",
        "tgt = \"survived\"\n",
        "\n",
        "# Eliminar filas donde el target es nulo\n",
        "df = df[~df[tgt].isnull()].copy()\n",
        "y = df[tgt].astype(int)\n",
        "\n",
        "# 4. División estratificada\n",
        "Xt, Xv, yt, yv = train_test_split(df[all_features], y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 5. Pipeline de preprocesamiento robusto\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors=5)),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('selector', SelectKBest(f_classif, k='all'))\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, num_features),\n",
        "        ('cat', categorical_transformer, cat_features)\n",
        "    ])\n",
        "\n",
        "# 6. Modelo de red neuronal con configuración robusta\n",
        "mlp = MLPClassifier(\n",
        "    early_stopping=True,\n",
        "    random_state=42,\n",
        "    max_iter=2000,\n",
        "    n_iter_no_change=50,\n",
        "    learning_rate='adaptive'\n",
        ")\n",
        "\n",
        "# 7. Pipeline completo\n",
        "pipe = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('mlp', mlp)\n",
        "])\n",
        "\n",
        "# 8. Espacio de búsqueda optimizado\n",
        "param_dist = {\n",
        "    'mlp__hidden_layer_sizes': [(100, 50), (150, 100, 50), (200, 100)],\n",
        "    'mlp__activation': ['relu', 'tanh'],\n",
        "    'mlp__alpha': [0.0001, 0.0005],\n",
        "    'mlp__learning_rate_init': [0.001, 0.005],\n",
        "    'mlp__batch_size': [32, 64],\n",
        "    'preprocessor__num__selector__k': [3, 4, 5]\n",
        "}\n",
        "\n",
        "# 9. Búsqueda de hiperparámetros con manejo robusto\n",
        "search = RandomizedSearchCV(\n",
        "    pipe,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=30,\n",
        "    cv=5,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"\\nEntrenando red neuronal optimizada...\")\n",
        "search.fit(Xt, yt)\n",
        "\n",
        "# 10. Evaluación y resultados\n",
        "best_model = search.best_estimator_\n",
        "\n",
        "# Función segura para evaluación\n",
        "def safe_evaluate(model, Xt, Xv, yt, yv):\n",
        "    try:\n",
        "        probas_train = model.predict_proba(Xt)[:, 1]\n",
        "        probas_val = model.predict_proba(Xv)[:, 1]\n",
        "\n",
        "        return {\n",
        "            'train_auc': roc_auc_score(yt, probas_train),\n",
        "            'val_auc': roc_auc_score(yv, probas_val),\n",
        "            'diff': abs(roc_auc_score(yt, probas_train) - roc_auc_score(yv, probas_val))\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error en evaluación: {str(e)}\")\n",
        "        return {'train_auc': 0, 'val_auc': 0, 'diff': 0}\n",
        "\n",
        "results = safe_evaluate(best_model, Xt, Xv, yt, yv)\n",
        "\n",
        "print(\"\\n=== Resultados Finales ===\")\n",
        "print(f\"AUC-ROC Entrenamiento: {results['train_auc']:.4f}\")\n",
        "print(f\"AUC-ROC Validación: {results['val_auc']:.4f}\")\n",
        "print(f\"Diferencia: {results['diff']:.4f}\")\n",
        "\n",
        "# 11. Verificación de objetivo\n",
        "if results['train_auc'] >= 0.85 and results['val_auc'] >= 0.85:\n",
        "    print(\"\\n¡Éxito: Modelo alcanzó el objetivo en ambos conjuntos!\")\n",
        "elif results['val_auc'] >= 0.85:\n",
        "    print(\"\\n¡Validación exitosa! Estrategias para mejorar entrenamiento:\")\n",
        "    print(\"- Aumentar capacidad del modelo (más neuronas/capas)\")\n",
        "    print(\"- Reducir regularización (disminuir alpha)\")\n",
        "    print(\"- Aumentar iteraciones de entrenamiento\")\n",
        "else:\n",
        "    print(\"\\nEstrategias para mejorar:\")\n",
        "    print(\"- Incrementar n_iter en la búsqueda (50-100)\")\n",
        "    print(\"- Probar arquitecturas más complejas (más capas ocultas)\")\n",
        "    print(\"- Añadir más características relevantes\")\n",
        "    print(\"- Usar técnicas avanzadas de imputación\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IIZjUlg6WXS",
        "outputId": "3800a70a-bdc6-4c59-9b29-aa7f930d4991"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entrenando red neuronal optimizada...\n",
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "\n",
            "=== Resultados Finales ===\n",
            "AUC-ROC Entrenamiento: 0.8525\n",
            "AUC-ROC Validación: 0.8846\n",
            "Diferencia: 0.0320\n",
            "\n",
            "¡Éxito: Modelo alcanzó el objetivo en ambos conjuntos!\n"
          ]
        }
      ]
    }
  ]
}